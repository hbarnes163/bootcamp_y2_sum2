{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\339755\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\339755\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\339755\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import nltk\n",
    "import urllib3\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "# Load the necessary NLTK resources and Spacy model\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('punkt')\n",
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully set web config settings for urllib, urllib3, requests\n"
     ]
    }
   ],
   "source": [
    "# Internal packages for setting web proxy and BOE configuration, can skip if not using a Bank of England device\n",
    "import boewebconnectpy\n",
    "boewebconnectpy.set_boe_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = urllib3.request(\"GET\", \"https://www.bankofengland.co.uk/stress-testing/2025/key-elements-bank-capital\", headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "\n",
    "r.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, utf8=True):\n",
    "    if utf8:\n",
    "        text = text.decode('utf-8')\n",
    "    text = text.replace('\\n', ' ').replace('\\r', '').replace('\\t', '')\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'{[^>]+}', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'\\.(\\[a-zA-Z])', r'. \\1', text)\n",
    "    text  = sent_tokenize(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully fetched data from https://www.bankofengland.co.uk/stress-testing/2025/key-elements-bank-capital\n",
      "Successfully fetched data from https://www.bankofengland.co.uk/stress-testing/2024/stress-testing-uk-banking-system-scenarios-2024-desk-based\n",
      "Successfully fetched data from https://www.bankofengland.co.uk/financial-stability-report/2024/november-2024#section6\n",
      "Successfully fetched data from https://www.bankofengland.co.uk/stress-testing/2024/boes-approach-to-stress-testing-the-uk-banking-system\n"
     ]
    }
   ],
   "source": [
    "url_list = [\"https://www.bankofengland.co.uk/stress-testing/2025/key-elements-bank-capital\",\n",
    "            \"https://www.bankofengland.co.uk/stress-testing/2024/stress-testing-uk-banking-system-scenarios-2024-desk-based\",\n",
    "            \"https://www.bankofengland.co.uk/financial-stability-report/2024/november-2024#section6\",\n",
    "            \"https://www.bankofengland.co.uk/stress-testing/2024/boes-approach-to-stress-testing-the-uk-banking-system\"]\n",
    "\n",
    "all_data = pd.DataFrame(columns=['OriginalSentence', 'Source'])\n",
    "for url in url_list:\n",
    "    r = urllib3.request(\"GET\", url, headers={\"User-Agent\": \"Mozilla/5.0\"})\n",
    "    if r.status == 200:\n",
    "        print(f\"Successfully fetched data from {url}\")\n",
    "        sentences = process_text(r.data)\n",
    "        sentences.pop(0)\n",
    "        sentence_data = pd.DataFrame(sentences, columns=['OriginalSentence'])\n",
    "        sentence_data['Source'] = url\n",
    "        sentence_data['Line'] = sentence_data.index + 1\n",
    "        all_data = pd.concat([all_data, sentence_data], ignore_index=True)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data from {url}, status code: {r.status}\")\n",
    "\n",
    "all_data = all_data.drop_duplicates().reset_index(drop=True)\n",
    "# Remove last line if contains it is 'Skip to main content'\n",
    "all_data = all_data[~all_data['OriginalSentence'].str.contains('Skip to main content', case=False, na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "len(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalSentence</th>\n",
       "      <th>Source</th>\n",
       "      <th>Line</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>NoStopwords</th>\n",
       "      <th>Numeric</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stress testing is used by the Bank to determin...</td>\n",
       "      <td>https://www.bankofengland.co.uk/stress-testing...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29</td>\n",
       "      <td>Stress testing used Bank determine UK banking ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>By doing so the Bank aims to ensure banks can ...</td>\n",
       "      <td>https://www.bankofengland.co.uk/stress-testing...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>82</td>\n",
       "      <td>Bank aims ensure banks absorb rather amplify s...</td>\n",
       "      <td>2025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rather, like previous concurrent stress test s...</td>\n",
       "      <td>https://www.bankofengland.co.uk/stress-testing...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58</td>\n",
       "      <td>Rather , like previous concurrent stress test ...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It is not a set of events that is expected, or...</td>\n",
       "      <td>https://www.bankofengland.co.uk/stress-testing...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17</td>\n",
       "      <td>set events expected , likely , materialise .</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This tail risk scenario is used for the purpos...</td>\n",
       "      <td>https://www.bankofengland.co.uk/stress-testing...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23</td>\n",
       "      <td>tail risk scenario used purposes enhancing fin...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    OriginalSentence  \\\n",
       "0  Stress testing is used by the Bank to determin...   \n",
       "1  By doing so the Bank aims to ensure banks can ...   \n",
       "2  Rather, like previous concurrent stress test s...   \n",
       "3  It is not a set of events that is expected, or...   \n",
       "4  This tail risk scenario is used for the purpos...   \n",
       "\n",
       "                                              Source  Line  WordCount  \\\n",
       "0  https://www.bankofengland.co.uk/stress-testing...   1.0         29   \n",
       "1  https://www.bankofengland.co.uk/stress-testing...   2.0         82   \n",
       "2  https://www.bankofengland.co.uk/stress-testing...   3.0         58   \n",
       "3  https://www.bankofengland.co.uk/stress-testing...   4.0         17   \n",
       "4  https://www.bankofengland.co.uk/stress-testing...   5.0         23   \n",
       "\n",
       "                                         NoStopwords Numeric  \n",
       "0  Stress testing used Bank determine UK banking ...          \n",
       "1  Bank aims ensure banks absorb rather amplify s...    2025  \n",
       "2  Rather , like previous concurrent stress test ...          \n",
       "3       set events expected , likely , materialise .          \n",
       "4  tail risk scenario used purposes enhancing fin...          "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"WordCount\"] = all_data['OriginalSentence'].apply(lambda x: len(word_tokenize(x)))\n",
    "all_data[\"NoStopwords\"] = all_data['OriginalSentence'].apply(lambda x: ' '.join([word for word in word_tokenize(x) if word.lower() not in stopwords]))\n",
    "all_data['Numeric'] = all_data['OriginalSentence'].apply(lambda x: nltk.pos_tag(word_tokenize(x))).apply(lambda x: ' '.join([word for word, pos in x if pos in ['CD']]))\n",
    "\n",
    "all_data = all_data[all_data['WordCount'] < 100]\n",
    "all_data = all_data[all_data['OriginalSentence'] != 'Measuring the stability of the banking system: capital and liquidity at risk with solvency-liquidity...']\n",
    "\n",
    "all_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in a file containing text to be tested against\n",
    "test = open(\"Stress Test 2026.txt\", \"r\")\n",
    "test_data = test.read()\n",
    "test.close()\n",
    "\n",
    "test = process_text(test_data, utf8=False)\n",
    "test_df = pd.DataFrame(test, columns=['OriginalSentence'])\n",
    "\n",
    "# Extract out numbers\n",
    "test_df['OriginalNumeric'] = test_df['OriginalSentence'].apply(lambda x: nltk.pos_tag(word_tokenize(x))).apply(lambda x: ' '.join([word for word, pos in x if pos in ['CD']]))\n",
    "numeric_df = test_df.copy()\n",
    "numeric_df = numeric_df[numeric_df['OriginalNumeric'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(sentence, all_data, min_threshold=0.75, perfect_threshold = 0.9, stopword = False):\n",
    "    if stopword == False:\n",
    "        sentence = sentence.join([word for word in word_tokenize(sentence) if word.lower() not in stopwords])\n",
    "    doc1 = nlp(sentence)\n",
    "    max_similarity = 0\n",
    "    for idx, row in all_data.iterrows():\n",
    "        if stopword == False:\n",
    "            doc2 = nlp(row['NoStopwords'])\n",
    "        else:\n",
    "            doc2 = nlp(row['OriginalSentence'])\n",
    "        similarity = doc1.similarity(doc2)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            if max_similarity >= perfect_threshold and max_similarity > min_threshold:\n",
    "                Similar = row['OriginalSentence']\n",
    "                SimilarSource = row['Source']\n",
    "                SimilarLine = row['Line']\n",
    "                SimilarityScore = max_similarity\n",
    "                break\n",
    "    if max_similarity > min_threshold:\n",
    "        Similar = row['OriginalSentence']\n",
    "        SimilarSource = row['Source']\n",
    "        SimilarLine = row['Line']\n",
    "        SimilarityScore = max_similarity\n",
    "    else:\n",
    "        Similar = \"None found\"\n",
    "        SimilarSource = None\n",
    "        SimilarLine = None\n",
    "        SimilarityScore = None\n",
    "    return Similar, SimilarSource, SimilarLine, SimilarityScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[[\"Similar\", \"SimilarSource\", \"SimilarLine\", \"SimilarityScore\"]] = test_df['OriginalSentence'].apply(lambda x: check_similarity(x, all_data, min_threshold=0.8, perfect_threshold=0.98)).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_numeric_match(row, all_data):\n",
    "    all_data['NumericMatch'] = all_data['Numeric'].apply(lambda x: re.search(row['OriginalNumeric'], x) is not None if x else False)\n",
    "    numeric_matches = all_data.copy()\n",
    "    numeric_matches = numeric_matches[numeric_matches['NumericMatch'] == True]\n",
    "    if numeric_matches.empty:\n",
    "        return 'None found', None, None, None, None\n",
    "    doc1 = nlp(row['OriginalSentence'])\n",
    "    numeric_matches['Similarity'] = numeric_matches['OriginalSentence'].apply(lambda x: nlp(x).similarity(doc1))\n",
    "    best_match = numeric_matches.loc[numeric_matches['Similarity'].idxmax()]\n",
    "    Match = best_match['Numeric']\n",
    "    Similar = best_match['OriginalSentence']\n",
    "    SimilarSource = best_match['Source']\n",
    "    SimilarLine = best_match['Line']\n",
    "    SimilarityScore = best_match['Similarity']\n",
    "    return Match, Similar, SimilarSource, SimilarLine, SimilarityScore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df[[\"NumericMatch\", \"SimilarNumeric\", \"NumericSimilarSource\", \"NumericSimilarLine\", \"NumericSimilarityScore\"]] = numeric_df.apply(lambda x: check_numeric_match(x, all_data), axis=1).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save results to a CSV file\n",
    "test_df[['AnalystNotes', 'AnalystSignOff', 'SignOffDate', 'IssuesObserved', 'AlternativeSourceUsed']] = \"\"\n",
    "numeric_df[['AnalystNotes', 'AnalystSignOff', 'SignOffDate', 'IssuesObserved', 'AlternativeSourceUsed']] = \"\"\n",
    "with pd.ExcelWriter('StressTest2026.xlsx') as writer:\n",
    "    test_df.to_excel(writer, sheet_name='Text', index= False)\n",
    "    numeric_df.to_excel(writer, sheet_name='Numeric', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "uni",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
